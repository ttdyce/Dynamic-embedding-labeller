{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "======] - 37s 67ms/sample - loss: 1.1457 - accuracy: 0.3425 - val_loss: 1.0883 - val_accuracy: 0.4818\nEpoch 2/100\n546/546 [==============================] - 26s 48ms/sample - loss: 1.0470 - accuracy: 0.5110 - val_loss: 1.0356 - val_accuracy: 0.5109\nEpoch 3/100\n546/546 [==============================] - 22s 39ms/sample - loss: 0.9911 - accuracy: 0.5220 - val_loss: 1.0073 - val_accuracy: 0.5547\nEpoch 4/100\n546/546 [==============================] - 23s 43ms/sample - loss: 0.9650 - accuracy: 0.5568 - val_loss: 0.9890 - val_accuracy: 0.5547\nEpoch 5/100\n546/546 [==============================] - 32s 58ms/sample - loss: 0.9469 - accuracy: 0.5568 - val_loss: 0.9735 - val_accuracy: 0.5547\nEpoch 6/100\n546/546 [==============================] - 30s 55ms/sample - loss: 0.9313 - accuracy: 0.5586 - val_loss: 0.9580 - val_accuracy: 0.5547\nEpoch 7/100\n546/546 [==============================] - 35s 64ms/sample - loss: 0.9157 - accuracy: 0.5586 - val_loss: 0.9426 - val_accuracy: 0.5547\nEpoch 8/100\n546/546 [==============================] - 35s 65ms/sample - loss: 0.9003 - accuracy: 0.5604 - val_loss: 0.9269 - val_accuracy: 0.5547\nEpoch 9/100\n546/546 [==============================] - 35s 63ms/sample - loss: 0.8835 - accuracy: 0.5659 - val_loss: 0.9084 - val_accuracy: 0.5474\nEpoch 10/100\n546/546 [==============================] - 36s 65ms/sample - loss: 0.8644 - accuracy: 0.5659 - val_loss: 0.8874 - val_accuracy: 0.5474\nEpoch 11/100\n546/546 [==============================] - 34s 63ms/sample - loss: 0.8410 - accuracy: 0.5696 - val_loss: 0.8610 - val_accuracy: 0.5474\nEpoch 12/100\n546/546 [==============================] - 35s 64ms/sample - loss: 0.8119 - accuracy: 0.5696 - val_loss: 0.8257 - val_accuracy: 0.5474\nEpoch 13/100\n546/546 [==============================] - 35s 64ms/sample - loss: 0.7686 - accuracy: 0.5678 - val_loss: 0.7749 - val_accuracy: 0.5401\nEpoch 14/100\n546/546 [==============================] - 38s 69ms/sample - loss: 0.7102 - accuracy: 0.5733 - val_loss: 0.7508 - val_accuracy: 0.5255\nEpoch 15/100\n546/546 [==============================] - 36s 66ms/sample - loss: 0.6835 - accuracy: 0.5861 - val_loss: 0.7536 - val_accuracy: 0.5474\nEpoch 16/100\n546/546 [==============================] - 42s 76ms/sample - loss: 0.6865 - accuracy: 0.5714 - val_loss: 0.7368 - val_accuracy: 0.5474\nEpoch 17/100\n546/546 [==============================] - 41s 76ms/sample - loss: 0.6836 - accuracy: 0.5916 - val_loss: 0.7392 - val_accuracy: 0.5474\nEpoch 18/100\n546/546 [==============================] - 40s 72ms/sample - loss: 0.6832 - accuracy: 0.5824 - val_loss: 0.7372 - val_accuracy: 0.5474\nEpoch 19/100\n546/546 [==============================] - 42s 76ms/sample - loss: 0.6829 - accuracy: 0.5916 - val_loss: 0.7434 - val_accuracy: 0.5474\nEpoch 20/100\n546/546 [==============================] - 41s 74ms/sample - loss: 0.6835 - accuracy: 0.5897 - val_loss: 0.7364 - val_accuracy: 0.5474\nEpoch 21/100\n546/546 [==============================] - 40s 74ms/sample - loss: 0.6845 - accuracy: 0.5678 - val_loss: 0.7384 - val_accuracy: 0.5474\nEpoch 22/100\n546/546 [==============================] - 34s 63ms/sample - loss: 0.6805 - accuracy: 0.5806 - val_loss: 0.7397 - val_accuracy: 0.5474\nEpoch 23/100\n546/546 [==============================] - 26s 48ms/sample - loss: 0.6830 - accuracy: 0.5788 - val_loss: 0.7374 - val_accuracy: 0.5474\nEpoch 24/100\n546/546 [==============================] - 27s 49ms/sample - loss: 0.6799 - accuracy: 0.5879 - val_loss: 0.7373 - val_accuracy: 0.5474\nEpoch 25/100\n546/546 [==============================] - 27s 49ms/sample - loss: 0.6805 - accuracy: 0.5879 - val_loss: 0.7374 - val_accuracy: 0.5547\nEpoch 26/100\n546/546 [==============================] - 27s 49ms/sample - loss: 0.6819 - accuracy: 0.5861 - val_loss: 0.7412 - val_accuracy: 0.5474\nEpoch 27/100\n546/546 [==============================] - 27s 49ms/sample - loss: 0.6804 - accuracy: 0.5696 - val_loss: 0.7355 - val_accuracy: 0.5547\nEpoch 28/100\n546/546 [==============================] - 27s 49ms/sample - loss: 0.6803 - accuracy: 0.5916 - val_loss: 0.7384 - val_accuracy: 0.5255\nEpoch 29/100\n546/546 [==============================] - 27s 49ms/sample - loss: 0.6801 - accuracy: 0.5842 - val_loss: 0.7372 - val_accuracy: 0.5474\nEpoch 30/100\n546/546 [==============================] - 27s 50ms/sample - loss: 0.6822 - accuracy: 0.5751 - val_loss: 0.7415 - val_accuracy: 0.5474\nEpoch 31/100\n546/546 [==============================] - 27s 50ms/sample - loss: 0.6829 - accuracy: 0.5751 - val_loss: 0.7391 - val_accuracy: 0.5255\nEpoch 32/100\n546/546 [==============================] - 26s 48ms/sample - loss: 0.6775 - accuracy: 0.5861 - val_loss: 0.7344 - val_accuracy: 0.5547\nEpoch 33/100\n546/546 [==============================] - 26s 47ms/sample - loss: 0.6782 - accuracy: 0.5806 - val_loss: 0.7347 - val_accuracy: 0.5620\nEpoch 34/100\n546/546 [==============================] - 27s 49ms/sample - loss: 0.6770 - accuracy: 0.5824 - val_loss: 0.7400 - val_accuracy: 0.5620\nEpoch 35/100\n546/546 [==============================] - 25s 45ms/sample - loss: 0.6768 - accuracy: 0.5861 - val_loss: 0.7382 - val_accuracy: 0.5620\nEpoch 36/100\n546/546 [==============================] - 24s 44ms/sample - loss: 0.6784 - accuracy: 0.5842 - val_loss: 0.7344 - val_accuracy: 0.5547\nEpoch 37/100\n546/546 [==============================] - 24s 44ms/sample - loss: 0.6758 - accuracy: 0.5842 - val_loss: 0.7361 - val_accuracy: 0.5620\nEpoch 38/100\n546/546 [==============================] - 24s 44ms/sample - loss: 0.6774 - accuracy: 0.5916 - val_loss: 0.7381 - val_accuracy: 0.5620\nEpoch 39/100\n546/546 [==============================] - 24s 45ms/sample - loss: 0.6749 - accuracy: 0.5916 - val_loss: 0.7358 - val_accuracy: 0.5620\nEpoch 40/100\n546/546 [==============================] - 24s 45ms/sample - loss: 0.6758 - accuracy: 0.5824 - val_loss: 0.7331 - val_accuracy: 0.5474\nEpoch 41/100\n546/546 [==============================] - 25s 46ms/sample - loss: 0.6738 - accuracy: 0.5916 - val_loss: 0.7366 - val_accuracy: 0.5474\nEpoch 42/100\n546/546 [==============================] - 26s 48ms/sample - loss: 0.6736 - accuracy: 0.5897 - val_loss: 0.7360 - val_accuracy: 0.5547\nEpoch 43/100\n546/546 [==============================] - 28s 51ms/sample - loss: 0.6735 - accuracy: 0.5971 - val_loss: 0.7345 - val_accuracy: 0.5620\nEpoch 44/100\n546/546 [==============================] - 25s 47ms/sample - loss: 0.6746 - accuracy: 0.5897 - val_loss: 0.7359 - val_accuracy: 0.5401\nEpoch 45/100\n546/546 [==============================] - 25s 46ms/sample - loss: 0.6702 - accuracy: 0.5861 - val_loss: 0.7330 - val_accuracy: 0.5547\nEpoch 46/100\n546/546 [==============================] - 25s 45ms/sample - loss: 0.6707 - accuracy: 0.6081 - val_loss: 0.7344 - val_accuracy: 0.5547\nEpoch 47/100\n546/546 [==============================] - 25s 46ms/sample - loss: 0.6700 - accuracy: 0.5916 - val_loss: 0.7334 - val_accuracy: 0.5474\nEpoch 48/100\n546/546 [==============================] - 26s 47ms/sample - loss: 0.6693 - accuracy: 0.6007 - val_loss: 0.7327 - val_accuracy: 0.5693\nEpoch 49/100\n546/546 [==============================] - 26s 47ms/sample - loss: 0.6682 - accuracy: 0.5971 - val_loss: 0.7350 - val_accuracy: 0.5401\nEpoch 50/100\n546/546 [==============================] - 26s 49ms/sample - loss: 0.6671 - accuracy: 0.5971 - val_loss: 0.7327 - val_accuracy: 0.5620\nEpoch 51/100\n546/546 [==============================] - 26s 48ms/sample - loss: 0.6656 - accuracy: 0.5989 - val_loss: 0.7323 - val_accuracy: 0.5401\nEpoch 52/100\n546/546 [==============================] - 26s 48ms/sample - loss: 0.6667 - accuracy: 0.6062 - val_loss: 0.7348 - val_accuracy: 0.5693\nEpoch 53/100\n546/546 [==============================] - 26s 47ms/sample - loss: 0.6637 - accuracy: 0.6026 - val_loss: 0.7309 - val_accuracy: 0.5401\nEpoch 54/100\n546/546 [==============================] - 26s 47ms/sample - loss: 0.6642 - accuracy: 0.5879 - val_loss: 0.7294 - val_accuracy: 0.5474\nEpoch 55/100\n546/546 [==============================] - 26s 48ms/sample - loss: 0.6631 - accuracy: 0.6136 - val_loss: 0.7352 - val_accuracy: 0.5693\nEpoch 56/100\n546/546 [==============================] - 26s 48ms/sample - loss: 0.6645 - accuracy: 0.5934 - val_loss: 0.7304 - val_accuracy: 0.5474\nEpoch 57/100\n546/546 [==============================] - 27s 49ms/sample - loss: 0.6613 - accuracy: 0.6081 - val_loss: 0.7332 - val_accuracy: 0.5620\nEpoch 58/100\n546/546 [==============================] - 25s 47ms/sample - loss: 0.6605 - accuracy: 0.6026 - val_loss: 0.7290 - val_accuracy: 0.5474\nEpoch 59/100\n546/546 [==============================] - 27s 50ms/sample - loss: 0.6583 - accuracy: 0.6099 - val_loss: 0.7298 - val_accuracy: 0.5693\nEpoch 60/100\n546/546 [==============================] - 25s 46ms/sample - loss: 0.6560 - accuracy: 0.6081 - val_loss: 0.7319 - val_accuracy: 0.5620\nEpoch 61/100\n546/546 [==============================] - 25s 47ms/sample - loss: 0.6561 - accuracy: 0.6081 - val_loss: 0.7294 - val_accuracy: 0.5693\nEpoch 62/100\n546/546 [==============================] - 26s 47ms/sample - loss: 0.6539 - accuracy: 0.6007 - val_loss: 0.7284 - val_accuracy: 0.5620\nEpoch 63/100\n546/546 [==============================] - 25s 46ms/sample - loss: 0.6513 - accuracy: 0.6026 - val_loss: 0.7280 - val_accuracy: 0.5620\nEpoch 64/100\n546/546 [==============================] - 26s 47ms/sample - loss: 0.6514 - accuracy: 0.6172 - val_loss: 0.7274 - val_accuracy: 0.5766\nEpoch 65/100\n546/546 [==============================] - 25s 45ms/sample - loss: 0.6482 - accuracy: 0.6099 - val_loss: 0.7293 - val_accuracy: 0.5693\nEpoch 66/100\n546/546 [==============================] - 25s 46ms/sample - loss: 0.6488 - accuracy: 0.6007 - val_loss: 0.7311 - val_accuracy: 0.5766\nEpoch 67/100\n546/546 [==============================] - 25s 46ms/sample - loss: 0.6470 - accuracy: 0.6209 - val_loss: 0.7276 - val_accuracy: 0.5839\nEpoch 68/100\n546/546 [==============================] - 25s 45ms/sample - loss: 0.6454 - accuracy: 0.6172 - val_loss: 0.7253 - val_accuracy: 0.5693\nEpoch 69/100\n546/546 [==============================] - 26s 47ms/sample - loss: 0.6447 - accuracy: 0.6300 - val_loss: 0.7258 - val_accuracy: 0.5766\nEpoch 70/100\n546/546 [==============================] - 25s 46ms/sample - loss: 0.6419 - accuracy: 0.6172 - val_loss: 0.7236 - val_accuracy: 0.5766\nEpoch 71/100\n546/546 [==============================] - 25s 45ms/sample - loss: 0.6431 - accuracy: 0.6319 - val_loss: 0.7267 - val_accuracy: 0.5912\nEpoch 72/100\n546/546 [==============================] - 25s 46ms/sample - loss: 0.6423 - accuracy: 0.6099 - val_loss: 0.7209 - val_accuracy: 0.5693\nEpoch 73/100\n546/546 [==============================] - 24s 45ms/sample - loss: 0.6386 - accuracy: 0.6264 - val_loss: 0.7245 - val_accuracy: 0.6058\nEpoch 74/100\n546/546 [==============================] - 25s 46ms/sample - loss: 0.6379 - accuracy: 0.6685 - val_loss: 0.7233 - val_accuracy: 0.6058\nEpoch 75/100\n546/546 [==============================] - 26s 47ms/sample - loss: 0.6366 - accuracy: 0.6209 - val_loss: 0.7231 - val_accuracy: 0.5985\nEpoch 76/100\n546/546 [==============================] - 26s 48ms/sample - loss: 0.6376 - accuracy: 0.6484 - val_loss: 0.7248 - val_accuracy: 0.6058\nEpoch 77/100\n546/546 [==============================] - 25s 46ms/sample - loss: 0.6316 - accuracy: 0.6502 - val_loss: 0.7177 - val_accuracy: 0.5912\nEpoch 78/100\n546/546 [==============================] - 26s 48ms/sample - loss: 0.6327 - accuracy: 0.6300 - val_loss: 0.7182 - val_accuracy: 0.6131\nEpoch 79/100\n546/546 [==============================] - 25s 46ms/sample - loss: 0.6314 - accuracy: 0.6575 - val_loss: 0.7197 - val_accuracy: 0.6131\nEpoch 80/100\n546/546 [==============================] - 25s 46ms/sample - loss: 0.6296 - accuracy: 0.6502 - val_loss: 0.7159 - val_accuracy: 0.6058\nEpoch 81/100\n546/546 [==============================] - 26s 47ms/sample - loss: 0.6274 - accuracy: 0.6538 - val_loss: 0.7152 - val_accuracy: 0.5985\nEpoch 82/100\n546/546 [==============================] - 25s 46ms/sample - loss: 0.6274 - accuracy: 0.6612 - val_loss: 0.7196 - val_accuracy: 0.6058\nEpoch 83/100\n546/546 [==============================] - 26s 47ms/sample - loss: 0.6274 - accuracy: 0.6410 - val_loss: 0.7131 - val_accuracy: 0.5985\nEpoch 84/100\n546/546 [==============================] - 27s 49ms/sample - loss: 0.6249 - accuracy: 0.6502 - val_loss: 0.7169 - val_accuracy: 0.5985\nEpoch 85/100\n546/546 [==============================] - 26s 48ms/sample - loss: 0.6224 - accuracy: 0.6630 - val_loss: 0.7100 - val_accuracy: 0.6131\nEpoch 86/100\n546/546 [==============================] - 40s 74ms/sample - loss: 0.6199 - accuracy: 0.6593 - val_loss: 0.7098 - val_accuracy: 0.6131\nEpoch 87/100\n546/546 [==============================] - 44s 81ms/sample - loss: 0.6200 - accuracy: 0.6593 - val_loss: 0.7106 - val_accuracy: 0.6058\nEpoch 88/100\n546/546 [==============================] - 36s 66ms/sample - loss: 0.6197 - accuracy: 0.6557 - val_loss: 0.7086 - val_accuracy: 0.6131\nEpoch 89/100\n546/546 [==============================] - 41s 75ms/sample - loss: 0.6173 - accuracy: 0.6538 - val_loss: 0.7080 - val_accuracy: 0.6131\nEpoch 90/100\n546/546 [==============================] - 34s 62ms/sample - loss: 0.6150 - accuracy: 0.6612 - val_loss: 0.7086 - val_accuracy: 0.5985\nEpoch 91/100\n546/546 [==============================] - 33s 61ms/sample - loss: 0.6150 - accuracy: 0.6593 - val_loss: 0.7074 - val_accuracy: 0.6131\nEpoch 92/100\n546/546 [==============================] - 37s 69ms/sample - loss: 0.6131 - accuracy: 0.6703 - val_loss: 0.7066 - val_accuracy: 0.6131\nEpoch 93/100\n546/546 [==============================] - 40s 74ms/sample - loss: 0.6110 - accuracy: 0.6685 - val_loss: 0.7043 - val_accuracy: 0.6204\nEpoch 94/100\n546/546 [==============================] - 43s 78ms/sample - loss: 0.6105 - accuracy: 0.6703 - val_loss: 0.7031 - val_accuracy: 0.6131\nEpoch 95/100\n546/546 [==============================] - 42s 76ms/sample - loss: 0.6088 - accuracy: 0.6685 - val_loss: 0.7042 - val_accuracy: 0.5985\nEpoch 96/100\n546/546 [==============================] - 41s 75ms/sample - loss: 0.6088 - accuracy: 0.6612 - val_loss: 0.7008 - val_accuracy: 0.6204\nEpoch 97/100\n546/546 [==============================] - 43s 78ms/sample - loss: 0.6046 - accuracy: 0.6703 - val_loss: 0.7045 - val_accuracy: 0.5985\nEpoch 98/100\n546/546 [==============================] - 43s 79ms/sample - loss: 0.6058 - accuracy: 0.6667 - val_loss: 0.7022 - val_accuracy: 0.6131\nEpoch 99/100\n546/546 [==============================] - 44s 80ms/sample - loss: 0.6048 - accuracy: 0.6612 - val_loss: 0.7009 - val_accuracy: 0.6131\nEpoch 100/100\n546/546 [==============================] - 45s 82ms/sample - loss: 0.6042 - accuracy: 0.6685 - val_loss: 0.6962 - val_accuracy: 0.6131\n\n# Evaluate\n171/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 1s 7ms/sample - loss: 0.6627 - accuracy: 0.5906\nINFO:tensorflow:Assets written to: rnn-trace/assets\n"
    }
   ],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import DatasetLoader as Loader\n",
    "\n",
    "batch_size_fit = 50\n",
    "# Each input sequence will be of size (28, 28) (height is treated like time).\n",
    "\n",
    "units = 200\n",
    "output_size = 3  # labels are from 0 to 3\n",
    "epochs = 100\n",
    "\n",
    "# Build the RNN model\n",
    "def build_model(allow_cudnn_kernel=True):\n",
    "    # CuDNN is only available at the layer level, and not at the cell level.\n",
    "    # This means `LSTM(units)` will use the CuDNN kernel,\n",
    "    # while RNN(LSTMCell(units)) will run on non-CuDNN kernel.\n",
    "    if allow_cudnn_kernel:\n",
    "        # The LSTM layer with default options uses CuDNN.\n",
    "        gru_layer = tf.keras.layers.GRU(units, input_shape=(300, 1))\n",
    "    else:\n",
    "        # Wrapping a LSTMCell in a RNN layer will not use CuDNN.\n",
    "        gru_layer = tf.keras.layers.GRU(\n",
    "            tf.keras.layers.LSTMCell(units), input_shape=(None, input_dim)\n",
    "        )\n",
    "\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            gru_layer,\n",
    "            #tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dense(output_size,activation='softmax'),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "x, y, lens, lenMax, _names, _counts = Loader.stateTrace.load()\n",
    "\n",
    "#x, y, lens, lenMax = loader().loadDefault()\n",
    "input_dim = lenMax\n",
    "\n",
    "model = build_model(allow_cudnn_kernel=True)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# print(\"x.shape\",x.shape)\n",
    "x = x.reshape(x.__len__(), 300, 1)\n",
    "print(\"x.shape\",x.shape)\n",
    "# print(y.shape)\n",
    "\n",
    "# print(x[0])\n",
    "# print(y[0])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(\n",
    "    x_train, y_train, batch_size=batch_size_fit, epochs=epochs, validation_split=0.2\n",
    ")\n",
    "\n",
    "print('\\n# Evaluate')\n",
    "result = model.evaluate(x_test,y_test)\n",
    "dict(zip(model.metrics_names, result))\n",
    "\n",
    "\n",
    "model.save('rnn-trace/', save_format=\"tf\")\n",
    "\n",
    "# model.predict(np.array([np.zeros(lenMax), np.ones(lenMax), np.full(lenMax, 999), np.full(lenMax, -1)]).reshape(4, 1, lenMax))\n",
    "\n",
    "# p = model.predict(Loader.variableTrace.loadPredition(lenMax, stack=True).reshape(12, 1, lenMax))\n",
    "# p1 = model.predict(Loader.variableTrace.loadPredition(lenMax)[0].reshape(4, 1, lenMax))\n",
    "# p2 = model.predict(Loader.variableTrace.loadPredition(lenMax)[1].reshape(4, 1, lenMax))\n",
    "# p3 = model.predict(Loader.variableTrace.loadPredition(lenMax)[2].reshape(4, 1, lenMax))\n",
    "\n",
    "# print([np.argmax(pp) for pp in p], sep='\\n')\n",
    "# print([np.argmax(p) for p in p1], sep='\\n')\n",
    "# print([np.argmax(p) for p in p2], sep='\\n')\n",
    "# print([np.argmax(p) for p in p3], sep='\\n')\n",
    "#prepared for predictions\n",
    "# Xnew = np.array([[0.89337759, 0.65864154]])\n",
    "# ynew = model.predict_classes(Xnew)\n",
    "# print(\"X=%s, Predicted=%s\" % (Xnew[0], ynew[0]))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}